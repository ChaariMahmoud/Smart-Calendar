{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b84b9-705b-4019-935a-6ca3b5f7b6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamoud/miniconda3/envs/tf/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/home/hamoud/miniconda3/envs/tf/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://192.168.1.42:5001\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from flask import Flask, request, jsonify\n",
    "import easyocr\n",
    "from torchvision import transforms\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import uuid\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize EasyOCR reader\n",
    "reader = easyocr.Reader(['en', 'fr'])  # Load the EasyOCR model for English and French\n",
    "\n",
    "# Ensure the use of GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Image preprocessing for EfficientNet\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Decode base64 image data\n",
    "def decode_image(base64_str):\n",
    "    if base64_str.startswith('data:image'):\n",
    "        base64_str = base64_str.split(',')[1]\n",
    "    img_data = base64.b64decode(base64_str)\n",
    "    nparr = np.frombuffer(img_data, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "def extract_text(image):\n",
    "    if image is None:\n",
    "        print(\"Image is None.\")\n",
    "    else:\n",
    "        print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    results = reader.readtext(image_rgb)  # Perform OCR\n",
    "\n",
    "    text = \" \".join([result[1] for result in results])  # Extract and concatenate text\n",
    "    return text\n",
    "\n",
    "def call_gemini_api(extracted_text):\n",
    "    genai.configure(api_key=\"AIzaSyDoi9e4M30hsQF1LmSOFgEdSRqwRdB3ctg\")\n",
    "\n",
    "    # Create the model\n",
    "    generation_config = {\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 64,\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    }\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "\n",
    "    chat_session = model.start_chat(\n",
    "        history=[]\n",
    "    )\n",
    "\n",
    "    response = chat_session.send_message(f\"\"\"\n",
    "    Please clean and correct the given sentences in English/French text and parse them into structured task details. Extract the date and time from the text and convert them to the formats 'mm/dd/yyyy' for dates and 'hh:mm' for times.\n",
    "\n",
    "    Handle both individual task images and calendar images from various sources (e.g., Teams, Android, iPhone). Correct any wrong data and handle missing data appropriately. If any data is missing in task title, task note, or task type, fill it with 'Unknown' or an appropriate placeholder.\n",
    "    If beginTime or endTime are not explicitly provided or missing, try to determine them through the context or use the current time for beginTime and predict the endTime based on the task details. \n",
    "    Predict task difficulty and task priority based on task information: they must take numbers from 1 to 5 for each one.\n",
    "\n",
    "    Additional rules:\n",
    "    - Correct text errors, e.g., \"Auoune réunion\" should be \"aucune réunion\". If it translates to \"no meeting\" or similar, exclude it from the events.\n",
    "    - For events containing \"Google Meet,\" format the text as \"REUNION TITLE DAY BEGINTIME ENDTIME PM/AM ...\".\n",
    "    - If the year is not specified, default to 2024.\n",
    "    \n",
    "    Output the result in a JSON format with the following keys:\n",
    "    - \"title\": \"Title content\",\n",
    "    - \"note\": \"Note content\",\n",
    "    - \"type\": \"Task type\",\n",
    "    - \"date\": \"mm/dd/yyyy\",\n",
    "    - \"beginTime\": \"hh:mm\",\n",
    "    - \"endTime\": \"hh:mm\",\n",
    "    - \"priority\": \"predicted priority value\",\n",
    "    - \"difficulty\": \"predicted difficulty value\"\n",
    "\n",
    "    Text to clean and parse: {extracted_text}\n",
    "    \"\"\")\n",
    "\n",
    "    return response.text\n",
    "\n",
    "@app.route('/api/extract_tasks', methods=['POST'])\n",
    "def extract_tasks():\n",
    "    data = request.json\n",
    "    image_data = data['imageData']\n",
    "    action = data['action']\n",
    "    user_id = data['userId']\n",
    "\n",
    "    original_img = decode_image(image_data)\n",
    "    extracted_text = extract_text(original_img)\n",
    "    print(f\"Extracted Text: {extracted_text}\")\n",
    "\n",
    "    gemini_response = call_gemini_api(extracted_text)\n",
    "    print(f\"Gemini API Response: {gemini_response}\")\n",
    "\n",
    "    try:\n",
    "        # Extract only the JSON array from the Gemini response\n",
    "        start_idx = gemini_response.find('[')\n",
    "        end_idx = gemini_response.rfind(']') + 1\n",
    "        json_response = gemini_response[start_idx:end_idx]\n",
    "        tasks = json.loads(json_response)  # Parse the JSON response\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decode error: {e}\")\n",
    "        return jsonify({\"message\": \"Failed to process task.\", \"error\": str(e)}), 400\n",
    "\n",
    "    backend_url = \"http://34.45.14.63:3000/api/tasks/tasks\"\n",
    "\n",
    "    if action == \"calendar\":\n",
    "        for task in tasks:\n",
    "            task_id = str(uuid.uuid4())  # Generate a unique UUID for each task\n",
    "            task[\"id\"] = task_id\n",
    "            task[\"_id\"] = task_id\n",
    "            task[\"userId\"] = user_id\n",
    "            task[\"color\"] = 1\n",
    "            task[\"successPercentage\"] = 0.0\n",
    "\n",
    "            print(f\"Task JSON before sending to backend (calendar): {json.dumps(task, indent=2)}\")  # Print the task JSON\n",
    "\n",
    "            response = requests.post(backend_url, json=task)\n",
    "            if response.status_code not in [200, 201]:\n",
    "                print(f\"Failed to add task {task_id}.\")\n",
    "                return jsonify({\"message\": f\"Failed to add task {task_id}.\"}), response.status_code\n",
    "\n",
    "        return jsonify({\"message\": \"All tasks processed successfully.\"}), 201\n",
    "\n",
    "    else:  # Single task scenario\n",
    "        task_id = data.get('taskId')\n",
    "        task = tasks[0]  # Assuming one task for non-calendar actions\n",
    "        task[\"id\"] = task_id\n",
    "        task[\"_id\"] = task_id\n",
    "        task[\"userId\"] = user_id\n",
    "        task[\"color\"] = 1\n",
    "        task[\"successPercentage\"] = 0.0\n",
    "\n",
    "        print(f\"Task JSON before sending to backend (single task): {json.dumps(task, indent=2)}\")  # Print the task JSON\n",
    "\n",
    "        if action == \"add\":\n",
    "            response = requests.post(backend_url, json=task)\n",
    "        elif action == \"update\":\n",
    "            response = requests.put(f\"{backend_url}/{task['_id']}\", json=task)\n",
    "\n",
    "        if response.status_code in [200, 201]:\n",
    "            return jsonify({\"message\": \"Task processed successfully.\"}), response.status_code\n",
    "        else:\n",
    "            return jsonify({\"message\": \"Failed to process task.\"}), response.status_code\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3ba4c-0838-4982-a027-d2acab259221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
