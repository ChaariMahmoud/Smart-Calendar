{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd8957f-fa2f-4848-8949-d34663cf36ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a34b5d-281d-486f-914f-de826eac5c8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libcupti.so.12: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytesseract\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m T5Tokenizer, T5ForConditionalGeneration\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     logging,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/transformers/utils/__init__.py:34\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     28\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     ContextManagers,\n\u001b[1;32m     36\u001b[0m     ExplicitEnum,\n\u001b[1;32m     37\u001b[0m     ModelOutput,\n\u001b[1;32m     38\u001b[0m     PaddingStrategy,\n\u001b[1;32m     39\u001b[0m     TensorType,\n\u001b[1;32m     40\u001b[0m     add_model_info_to_auto_map,\n\u001b[1;32m     41\u001b[0m     add_model_info_to_custom_pipelines,\n\u001b[1;32m     42\u001b[0m     cached_property,\n\u001b[1;32m     43\u001b[0m     can_return_loss,\n\u001b[1;32m     44\u001b[0m     expand_dims,\n\u001b[1;32m     45\u001b[0m     filter_out_non_signature_kwargs,\n\u001b[1;32m     46\u001b[0m     find_labels,\n\u001b[1;32m     47\u001b[0m     flatten_dict,\n\u001b[1;32m     48\u001b[0m     infer_framework,\n\u001b[1;32m     49\u001b[0m     is_jax_tensor,\n\u001b[1;32m     50\u001b[0m     is_numpy_array,\n\u001b[1;32m     51\u001b[0m     is_tensor,\n\u001b[1;32m     52\u001b[0m     is_tf_symbolic_tensor,\n\u001b[1;32m     53\u001b[0m     is_tf_tensor,\n\u001b[1;32m     54\u001b[0m     is_torch_device,\n\u001b[1;32m     55\u001b[0m     is_torch_dtype,\n\u001b[1;32m     56\u001b[0m     is_torch_tensor,\n\u001b[1;32m     57\u001b[0m     reshape,\n\u001b[1;32m     58\u001b[0m     squeeze,\n\u001b[1;32m     59\u001b[0m     strtobool,\n\u001b[1;32m     60\u001b[0m     tensor_size,\n\u001b[1;32m     61\u001b[0m     to_numpy,\n\u001b[1;32m     62\u001b[0m     to_py_obj,\n\u001b[1;32m     63\u001b[0m     torch_float,\n\u001b[1;32m     64\u001b[0m     torch_int,\n\u001b[1;32m     65\u001b[0m     transpose,\n\u001b[1;32m     66\u001b[0m     working_or_temp_dir,\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     69\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     70\u001b[0m     HF_MODULES_CACHE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m     try_to_load_from_cache,\n\u001b[1;32m     97\u001b[0m )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     99\u001b[0m     ACCELERATE_MIN_VERSION,\n\u001b[1;32m    100\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     torch_only_method,\n\u001b[1;32m    220\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/transformers/utils/generic.py:462\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_torch_pytree\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_model_output_flatten\u001b[39m(output: ModelOutput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Any], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_pytree.Context\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mvalues()), \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/__init__.py:237\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    236\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: libcupti.so.12: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import cv2\n",
    "import pytesseract\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c50b5-13f1-4c07-bce3-73417694d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize T5 model and tokenizer\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "\n",
    "# Initialize Sentence Transformer for retrieval\n",
    "retriever = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Initialize EfficientNet for image processing\n",
    "efficient_net = EfficientNetB0(include_top=False, weights='imagenet')\n",
    "\n",
    "@app.route('/process-image', methods=['POST'])\n",
    "def process_image():\n",
    "    data = request.json\n",
    "    image_data = data.get('imageData')\n",
    "    action = data.get('action')  # \"add\" or \"update\"\n",
    "    task_id = data.get('taskId')  # Only used for updating\n",
    "    \n",
    "    # Decode base64 string to image\n",
    "    image = decode_base64_image(image_data)\n",
    "    \n",
    "    # Extract text using OCR\n",
    "    extracted_text = extract_text(image)\n",
    "    \n",
    "    # Retrieve related documents and predict task details\n",
    "    task_details = predict_task_details(extracted_text)\n",
    "    \n",
    "    # Determine the action and call the appropriate API\n",
    "    if action == \"add\":\n",
    "        response = add_task(task_details)\n",
    "    elif action == \"update\" and task_id:\n",
    "        response = update_task(task_id, task_details)\n",
    "    else:\n",
    "        response = {\"status\": \"error\", \"message\": \"Invalid action or missing taskId\"}\n",
    "    \n",
    "    return jsonify(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9034bb-6a6d-4e82-9e19-a65bced5a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def decode_base64_image(base64_str):\n",
    "    decoded_data = base64.b64decode(base64_str)\n",
    "    np_data = np.frombuffer(decoded_data, np.uint8)\n",
    "    image = cv2.imdecode(np_data, cv2.IMREAD_COLOR)\n",
    "    return Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def extract_text(image):\n",
    "    gray_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
    "    extracted_text = pytesseract.image_to_string(gray_image)\n",
    "    return extracted_text\n",
    "\n",
    "def predict_task_details(extracted_text):\n",
    "    related_docs = retrieve_related_documents(extracted_text)\n",
    "    \n",
    "    combined_input = f\"Task details: {extracted_text} {related_docs}\"\n",
    "    \n",
    "    inputs = t5_tokenizer.encode(combined_input, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = t5_model.generate(inputs, max_length=150, num_beams=5, early_stopping=True)\n",
    "    generated_text = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    task_details = parse_generated_text(generated_text)\n",
    "    \n",
    "    # Ensure priority and difficulty are between 1 and 5\n",
    "    task_details['priority'] = max(1, min(5, task_details.get('priority', 1)))\n",
    "    task_details['difficulty'] = max(1, min(5, task_details.get('difficulty', 1)))\n",
    "    \n",
    "    return task_details\n",
    "\n",
    "def retrieve_related_documents(query):\n",
    "    # Example function to retrieve related documents or knowledge\n",
    "    related_docs = \"Example related document content\"\n",
    "    return related_docs\n",
    "\n",
    "def parse_generated_text(generated_text):\n",
    "    # Implement parsing logic based on your needs\n",
    "    task_details = {\n",
    "        \"title\": \"Predicted Title\",\n",
    "        \"note\": \"Generated Note\",\n",
    "        \"type\": \"Generated Type\",\n",
    "        \"date\": \"Predicted Date\",\n",
    "        \"beginTime\": \"Predicted BeginTime\",\n",
    "        \"endTime\": \"Predicted EndTime\",\n",
    "        \"priority\": extract_priority_from_text(generated_text),  # Extract priority from text\n",
    "        \"difficulty\": extract_difficulty_from_text(generated_text),  # Extract difficulty from text\n",
    "    }\n",
    "    return task_details\n",
    "\n",
    "def extract_priority_from_text(text):\n",
    "    # Example logic to extract priority from text\n",
    "    # Replace with actual extraction logic\n",
    "    return int(text.split('priority:')[1].strip().split()[0])\n",
    "\n",
    "def extract_difficulty_from_text(text):\n",
    "    # Example logic to extract difficulty from text\n",
    "    # Replace with actual extraction logic\n",
    "    return int(text.split('difficulty:')[1].strip().split()[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0def9d-4ab1-4fe1-9c04-19ec6a90c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_task(task_details):\n",
    "    url = \"http://127.0.0.1:3000/api/tasks/tasks\"\n",
    "    response = requests.post(url, json=task_details)\n",
    "    if response.status_code == 201:\n",
    "        return {\"status\": \"success\", \"message\": \"Task added successfully\"}\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"message\": f\"Failed to add task: {response.status_code}\"}\n",
    "\n",
    "def update_task(task_id, task_details):\n",
    "    url = f\"http://127.0.0.1:3000/api/tasks/tasks/{task_id}\"\n",
    "    response = requests.put(url, json=task_details)\n",
    "    if response.status_code == 200:\n",
    "        return {\"status\": \"success\", \"message\": \"Task updated successfully\"}\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"message\": f\"Failed to update task: {response.status_code}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7857fdc-74d9-4874-b850-bbd414158c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_model():\n",
    "    base_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # Add LSTM layer\n",
    "    x = LSTM(256, return_sequences=False)(x)\n",
    "    \n",
    "    # Output layers for task details\n",
    "    priority_output = Dense(1, activation='sigmoid')(x)  # Adjust based on your range (1-5)\n",
    "    difficulty_output = Dense(1, activation='sigmoid')(x)  # Adjust based on your range (1-5)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=[priority_output, difficulty_output])\n",
    "    model.compile(optimizer='adam', loss=['mse', 'mse'], metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
